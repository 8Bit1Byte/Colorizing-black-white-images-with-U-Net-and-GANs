{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Colorization using U-Net and GANs\n",
    "\n",
    "## Steps followed\n",
    "\n",
    "#### 1. Importing Necessary Libraries\n",
    "#### 2. Fetching The Dataset and Setting Up Input Paths\n",
    "#### 3. Defining Train and Test DataLoaders¶\n",
    "#### 4. Modeling the Conditional GAN\n",
    "#### 5. Defining Helper Functions\n",
    "#### 6. Initializing The Model\n",
    "#### 7. Training\n",
    "#### 8. Visualizing Loss Trajectory\n",
    "#### 9. Visualizing Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Importing necessary libraries and Setting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gs\n",
    "from matplotlib import font_manager as fm, rcParams\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Fetching The Dataset and Setting Up Input Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing fastai for Quickly Getting The COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U fastai\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing The Dataset in the Following Directory Structure\n",
    "<pre>\n",
    ".\n",
    "└── .fastai\n",
    "    └── data\n",
    "        └── coco_sample\n",
    "            └── train_sample\n",
    "                └── *.jpg (10,000 images in total)</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.external import untar_data, URLs\n",
    "coco_path = untar_data(URLs.COCO_SAMPLE)\n",
    "coco_path = str(coco_path) + \"/train_sample\"\n",
    "paths = glob.glob(coco_path + \"/*.jpg\")\n",
    "# Setting seed for getting the same data across all train sessions \n",
    "np.random.seed(123)\n",
    "paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 10000 images randomly\n",
    "rand_idxs = np.random.permutation(10_000)\n",
    "train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n",
    "val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(train_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing The Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCount = 0\n",
    "fig, ax = plt.subplots(4, 4, figsize=(13,13))\n",
    "for i in range(4):\n",
    "    for j in range(4):    \n",
    "        ax[i, j].imshow(Image.open(train_paths[imageCount]))\n",
    "        imageCount+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Defining Train and Test Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageSize = 256\n",
    "class MakeDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transforms = transforms.Compose([\n",
    "                transforms.Resize((ImageSize, ImageSize),  transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(), # Added after 350th Epoch to see if Results improves\n",
    "            ])\n",
    "        self.paths=paths\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = Image.open(self.paths[i])\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        imgInLAB = rgb2lab(img).astype(\"float32\")\n",
    "        imgInLAB = transforms.ToTensor()(imgInLAB)\n",
    "        L_array = imgInLAB[[0], ...] / 50. - 1.\n",
    "        ab_array = imgInLAB[[1, 2], ...] / 110.\n",
    "        return [L_array, ab_array]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dataloaders with input images transformed to L and ab image space, after resizing to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize, Workers = [16, 4]\n",
    "trainDL = DataLoader(MakeDataset(paths=train_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)\n",
    "validationDL = DataLoader(MakeDataset(paths=val_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the Transformed Data\n",
    "##### Helper Function for Converting a batch of Lab images into a batch of RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab):  \n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainDL))\n",
    "L_Array, ab_Array = data[0], data[1]\n",
    "print(f\"L Array Shape : {L_Array.shape}\", f\"*a*b Array Shape : {ab_Array.shape}\",sep='\\n')\n",
    "\n",
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(15,10))\n",
    "ax0.imshow(L_Array[0][0], cmap='gray')\n",
    "ax0.set_title('L')\n",
    "ax1.imshow(ab_Array[0][0])\n",
    "ax1.set_title('a')\n",
    "ax2.imshow(ab_Array[0][1])\n",
    "ax2.set_title('b')\n",
    "ax3.imshow(lab_to_rgb(L_Array,ab_Array)[0])\n",
    "ax3.set_title('RGB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Modeling the Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenBlock(nn.Module):\n",
    "    def __init__(self, inputs, outputs, down=True, batchNorm=True, dropout=False):\n",
    "        super(GenBlock,self).__init__()\n",
    "\n",
    "        if down:\n",
    "            self.block1 = nn.Conv2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            self.block4 = nn.LeakyReLU(0.2, True)\n",
    "        else:\n",
    "            self.block1 = nn.ConvTranspose2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            self.block4 = nn.ReLU(True)\n",
    "        if batchNorm:\n",
    "            self.block2 = nn.BatchNorm2d(outputs)\n",
    "        if dropout:\n",
    "            self.block3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.batchNorm = batchNorm\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        if self.batchNorm:\n",
    "            out = self.block2(out)\n",
    "        if self.dropout:\n",
    "            out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, inputs=1):\n",
    "        super(Generator,self).__init__()\n",
    "        \n",
    "        self.d1=  GenBlock(inputs,64,batchNorm=False)\n",
    "        self.d2=  GenBlock(64,128)\n",
    "        self.d3=  GenBlock(128,256)\n",
    "        self.d4=  GenBlock(256,512)\n",
    "        self.d5=  GenBlock(512,512)\n",
    "        self.d6=  GenBlock(512,512)\n",
    "        self.d7=  GenBlock(512,512)\n",
    "        self.d8=  nn.Sequential(nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.u1 = GenBlock(512,512,False,dropout=True)\n",
    "        self.u2 = GenBlock(1024,512,False,dropout=True)\n",
    "        self.u3 = GenBlock(1024,512,False,dropout=True)\n",
    "        self.u4 = GenBlock(1024,512,False)\n",
    "        self.u5 = GenBlock(1024,256,False)\n",
    "        self.u6 = GenBlock(512,128,False)\n",
    "        self.u7 = GenBlock(256,64,False)\n",
    "        self.u8 = nn.Sequential(nn.ConvTranspose2d(128, 2, kernel_size=4, stride=2, padding=1, bias=False), nn.Tanh())\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        dd1 = self.d1(x)\n",
    "        dd2 = self.d2(dd1)\n",
    "        dd3 = self.d3(dd2)\n",
    "        dd4 = self.d4(dd3)\n",
    "        dd5 = self.d5(dd4)\n",
    "        dd6 = self.d6(dd5)\n",
    "        dd7 = self.d7(dd6)\n",
    "        dd8 = self.d8(dd7)\n",
    "        uu1 = self.u1(dd8)\n",
    "        uu2 = self.u2(torch.concat([uu1,dd7],1)) #Skip Connection from dd7 to uu1\n",
    "        uu3 = self.u3(torch.concat([uu2,dd6],1))\n",
    "        uu4 = self.u4(torch.concat([uu3,dd5],1))\n",
    "        uu5 = self.u5(torch.concat([uu4,dd4],1))\n",
    "        uu6 = self.u6(torch.concat([uu5,dd3],1))\n",
    "        uu7 = self.u7(torch.concat([uu6,dd2],1))\n",
    "        uu8 = self.u8(torch.concat([uu7,dd1],1))\n",
    "        return uu8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGenerator=Generator(1)\n",
    "summary(testGenerator,(1,ImageSize,ImageSize),batch_size=BatchSize,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscBlock(nn.Module):\n",
    "    def __init__(self, inputs, outputs,  kernel=4, stride=2, padding=1, batchNorm=True, activation=True):\n",
    "        super(DiscBlock,self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Conv2d(inputs, outputs, kernel, stride, padding, bias=not batchNorm)\n",
    "        if batchNorm: self.block2 = nn.BatchNorm2d(outputs)\n",
    "        if activation: self.block3 = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "        self.batchNorm = batchNorm\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        if self.batchNorm:\n",
    "            out = self.block2(out)\n",
    "        if self.activation:\n",
    "            out = self.block3(out)\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, inputs=3):\n",
    "        super(Discriminator,self).__init__()\n",
    "\n",
    "        self.b1 = DiscBlock(inputs,64,batchNorm=False)\n",
    "        self.b2 = DiscBlock(64,128)\n",
    "        self.b3 = DiscBlock(128,256)\n",
    "        self.b4 = DiscBlock(256,512,stride=1)\n",
    "        self.b5 = DiscBlock(512,1,stride=1,batchNorm=False,activation=False)\n",
    "                                \n",
    "    def forward(self, x):\n",
    "        #print(x.shape())\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(y1)\n",
    "        y3 = self.b3(y2)\n",
    "        y4 = self.b4(y3)\n",
    "        y5 = self.b5(y4)\n",
    "        return y5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDiscriminator=Discriminator(3)\n",
    "summary(testDiscriminator,(3,ImageSize,ImageSize),batch_size=BatchSize,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Defining Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Generating Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowSamples(Model, dl, folder='./', epoch= -1, SAVE = True,suffix=\"\"):\n",
    "    data = next(iter(dl))\n",
    "    L, ab = data[0], data[1]\n",
    "    L=L.to(device)\n",
    "    ab=ab.to(device)\n",
    "    #Setting Model to Evaluation Mode. This disables layers like dropout\n",
    "    Model.eval()\n",
    "    with torch.no_grad():\n",
    "        abGenerated = Model(L)\n",
    "    Model.train()\n",
    "    inputImages = lab_to_rgb(L, ab)\n",
    "    generatedImages = lab_to_rgb(L, abGenerated)\n",
    "    row,col,img = 1,3,5  #Row = Number of samples generated per run (Keep it smaller than ${BatchSize}, Col=constant, img = Image size.\n",
    "    fig = plt.figure(figsize=(col*img, row*img))\n",
    "    gs1 = gs.GridSpec(nrows=row,ncols=col)\n",
    "    for i in range(row):\n",
    "        ax = plt.subplot(gs1[i,0])\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title('Grayscale',fontsize=16, fontweight='bold')\n",
    "        ax = plt.subplot(gs1[i,1])\n",
    "        ax.imshow(generatedImages[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title('Prediction',fontsize=16, fontweight='bold')\n",
    "        ax = plt.subplot(gs1[i,2])\n",
    "        ax.imshow(inputImages[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title('Ground Truth',fontsize=16, fontweight='bold') \n",
    "        \n",
    "    plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    if SAVE:\n",
    "        now = datetime.now()\n",
    "        currentTime = now.strftime(\"%H:%M:%S\")\n",
    "        fig.savefig(folder + f\"/Results_After_Epoch_{epoch}{suffix}_{currentTime}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Visualizing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualizeLoss(lossArr, folder, epoch, generator = True, SAVE = True):\n",
    "    x=(range(0,len(lossArr)))\n",
    "    plt.figure(figsize = (12,10))\n",
    "    plt.plot(x,lossArr)\n",
    "    str = \"Discriminator\"\n",
    "    if generator:\n",
    "        str = \"Generator\"\n",
    "        \n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(str + \" Loss\")\n",
    "    if SAVE:\n",
    "        now = datetime.now()\n",
    "        currentTime = now.strftime(\"%H:%M:%S\")\n",
    "        plt.savefig(folder + f\"/{str}_Loss_After_Epoch_{epoch}_{currentTime}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualizeAvgLoss(lossArr, folder, epoch, generator = True, SAVE = True, windowSize=5):\n",
    "    x=(range(0,len(lossArr)))\n",
    "    \n",
    "    averageY = []\n",
    "    sum = np.sum(lossArr[0:windowSize-1])\n",
    "    for ind in range(len(lossArr) - windowSize + 1):\n",
    "        sum+=lossArr[ind+windowSize-1]\n",
    "        averageY.append(sum/windowSize)\n",
    "        sum-=lossArr[ind]\n",
    "        \n",
    "    for ind in range(windowSize - 1):\n",
    "        averageY.insert(0, np.nan)\n",
    "        \n",
    "    plt.figure(figsize = (12,10))\n",
    "    plt.plot(x,averageY)\n",
    "    str = \"Discriminator\"\n",
    "    if generator:\n",
    "        str = \"Generator\"\n",
    "        \n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(str + \" Loss\")\n",
    "    if SAVE:\n",
    "        now = datetime.now()\n",
    "        currentTime = now.strftime(\"%H:%M:%S\")\n",
    "        plt.savefig(folder + f\"/{str}_Average_Loss_After_Epoch_{epoch}_WindowSize_{windowSize}_{currentTime}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Initializing The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4\n",
    "EPOCHS = 950\n",
    "LAMBDA = 100 #Discriminator L1 Loss Hyperparameter as Defined in the Pix2Pix Paper \n",
    "epoch = 1\n",
    "BETAS = (0.5,0.999) #Optimizer Hyperparameter as Defined in the Pix2Pix Paper\n",
    "lossOfDiscriminator = []\n",
    "lossOfGenerator = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and Logic for Loading and Saving Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = \"../input/model-params\"\n",
    "outputFolder = \"/kaggle/working\"\n",
    "checkpointPathDiscriminator = inputFolder+\"/disc.pth.tar\"\n",
    "checkpointPathGenerator = inputFolder+\"/gen.pth.tar\"\n",
    "loadModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveCheckpoint(model, optimizer, epoch, filename):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epoch\":epoch,\n",
    "        \"DISC_LOSS\" : lossOfDiscriminator,\n",
    "        \"GEN_LOSS\" : lossOfGenerator\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "def LoadCheckpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    global epoch\n",
    "    global lossOfDiscriminator\n",
    "    global lossOfGenerator\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    lossOfDiscriminator = checkpoint[\"DISC_LOSS\"].copy()\n",
    "    lossOfGenerator = checkpoint[\"GEN_LOSS\"].copy()\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discModel = Discriminator(3).to(device)\n",
    "genModel = Generator(1).to(device)\n",
    "optimizerForDiscriminator = optim.Adam(discModel.parameters(),lr=LEARNING_RATE, betas=BETAS)\n",
    "optimizerForGenerator = optim.Adam(genModel.parameters(),lr=LEARNING_RATE, betas=BETAS)\n",
    "LossFunction = nn.BCEWithLogitsLoss()\n",
    "L1Loss = nn.L1Loss()\n",
    "#Float 16 Training for faster Training\n",
    "discriminatorScaler = torch.cuda.amp.GradScaler()\n",
    "generatorScaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Previously Saved Checkpoint if Applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModel:\n",
    "    LoadCheckpoint(checkpointPathGenerator, genModel, optimizerForGenerator, LEARNING_RATE)\n",
    "    LoadCheckpoint(checkpointPathDiscriminator, discModel, optimizerForDiscriminator, LEARNING_RATE)\n",
    "\n",
    "    SaveModel = True\n",
    "\n",
    "checkpointPathDiscriminator = outputFolder+\"/disc.pth.tar\"\n",
    "checkpointPathGenerator = outputFolder+\"/gen.pth.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainFunction(discModel, genModel, loader, optimizerForDiscriminator, optimizerForGenerator, L1Loss, BCELoss, generatorScaler, discriminatorScaler):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for idx, (L, ab) in enumerate(loop):\n",
    "        L = L.to(device)\n",
    "        ab = ab.to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            YGenerated = genModel(L)\n",
    "            discReal = discModel(torch.concat([L, ab],1))\n",
    "            discRealLoss = BCELoss(discReal, torch.ones_like(discReal))\n",
    "            discGenerated = discModel(torch.concat([L, YGenerated.detach()],1))\n",
    "            discGeneratedLoss = BCELoss(discGenerated, torch.zeros_like(discGenerated))\n",
    "            discriminatorLoss = (discRealLoss + discGeneratedLoss) / 2\n",
    "            lossOfDiscriminator.append(discriminatorLoss.item())\n",
    "        discModel.zero_grad()\n",
    "        discriminatorScaler.scale(discriminatorLoss).backward()\n",
    "        discriminatorScaler.step(optimizerForDiscriminator)\n",
    "        discriminatorScaler.update()\n",
    "        \n",
    "        # Train generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            discGenerated = discModel(torch.concat([L, YGenerated],1))\n",
    "            genGeneratedLoss = BCELoss(discGenerated, torch.ones_like(discGenerated))\n",
    "            L1 = L1Loss(YGenerated, ab) * LAMBDA\n",
    "            generatorLoss = genGeneratedLoss + L1\n",
    "            lossOfGenerator.append(generatorLoss.item())\n",
    "\n",
    "        optimizerForGenerator.zero_grad()\n",
    "        generatorScaler.scale(generatorLoss).backward()\n",
    "        generatorScaler.step(optimizerForGenerator)\n",
    "        generatorScaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=True \n",
    "visualizeWhileTraining=True\n",
    "saveImages = True #To Save Images during visualization\n",
    "\n",
    "while TRAIN and (epoch <= EPOCHS):\n",
    "    print(\"\\nEpoch\",epoch,'\\n')\n",
    "    \n",
    "    if visualizeWhileTraining:\n",
    "        ShowSamples(genModel, validationDL,outputFolder,epoch,saveImages)\n",
    "        \n",
    "        print(\"Generator Loss\\n\")\n",
    "        VisualizeLoss(lossOfGenerator,outputFolder,epoch,True,saveImages)\n",
    "        print(\"Discriminator Loss\\n\")\n",
    "        VisualizeLoss(lossOfDiscriminator,outputFolder,epoch,False,saveImages)\n",
    "        \n",
    "    if SaveModel:\n",
    "        SaveCheckpoint(genModel, optimizerForGenerator, epoch, filename=checkpointPathGenerator)\n",
    "        SaveCheckpoint(discModel, optimizerForDiscriminator, epoch, filename=checkpointPathDiscriminator)\n",
    "\n",
    "    TrainFunction(discModel, genModel, trainDL, optimizerForDiscriminator, optimizerForGenerator, L1Loss, LossFunction, discriminatorScaler, generatorScaler)\n",
    "    \n",
    "    epoch+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Visualizing Loss Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizeAvgLoss(lossArr=lossOfGenerator,folder=outputFolder,epoch=epoch,generator=True,SAVE=True,windowSize=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizeLoss(lossArr=lossOfGenerator,folder=outputFolder,epoch=epoch,generator=True,SAVE=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizeAvgLoss(lossArr=lossOfDiscriminator,folder=outputFolder,epoch=epoch,generator=False,SAVE=True,windowSize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisualizeLoss(lossArr=lossOfDiscriminator,folder=outputFolder,epoch=epoch,generator=False,SAVE=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Visualizing Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRuns = 200 #Generate numRuns*5 Samples\n",
    "for run in range(numRuns):\n",
    "    ShowSamples(genModel, trainDL,outputFolder,epoch,SAVE=True,suffix=\"_On_Training_Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(numRuns):\n",
    "    ShowSamples(genModel, validationDL,outputFolder,epoch,SAVE=True, suffix=\"_On_Validation_set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13dd93a277554efb33d9dc9352f7e61f8b4dd00a9187561e5f5d511fdca2ba07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
